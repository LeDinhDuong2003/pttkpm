{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6212,"status":"ok","timestamp":1747374559911,"user":{"displayName":"L√™ ƒê√¨nh D∆∞∆°ng - B21DCCN281","userId":"05329236511620356760"},"user_tz":-420},"id":"CNj2wDM4X5mW","outputId":"d54ebfdb-0eb2-4f31-ea5d-f82606b295ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting fastapi\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n","Collecting pyngrok\n","  Downloading pyngrok-7.2.8-py3-none-any.whl.metadata (10 kB)\n","Collecting uvicorn\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Collecting mysql-connector-python\n","  Downloading mysql_connector_python-9.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n","Collecting starlette\u003c0.47.0,\u003e=0.40.0 (from fastapi)\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,\u003c3.0.0,\u003e=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.4)\n","Requirement already satisfied: typing-extensions\u003e=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n","Requirement already satisfied: PyYAML\u003e=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: click\u003e=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.0)\n","Requirement already satisfied: h11\u003e=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n","Requirement already satisfied: annotated-types\u003e=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,\u003c3.0.0,\u003e=1.7.4-\u003efastapi) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,\u003c3.0.0,\u003e=1.7.4-\u003efastapi) (2.33.2)\n","Requirement already satisfied: typing-inspection\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,\u003c3.0.0,\u003e=1.7.4-\u003efastapi) (0.4.0)\n","Requirement already satisfied: anyio\u003c5,\u003e=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette\u003c0.47.0,\u003e=0.40.0-\u003efastapi) (4.9.0)\n","Requirement already satisfied: idna\u003e=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio\u003c5,\u003e=3.6.2-\u003estarlette\u003c0.47.0,\u003e=0.40.0-\u003efastapi) (3.10)\n","Requirement already satisfied: sniffio\u003e=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio\u003c5,\u003e=3.6.2-\u003estarlette\u003c0.47.0,\u003e=0.40.0-\u003efastapi) (1.3.1)\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyngrok-7.2.8-py3-none-any.whl (25 kB)\n","Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mysql_connector_python-9.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (33.9 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: uvicorn, pyngrok, mysql-connector-python, starlette, fastapi\n","Successfully installed fastapi-0.115.12 mysql-connector-python-9.3.0 pyngrok-7.2.8 starlette-0.46.2 uvicorn-0.34.2\n"]}],"source":["!pip install fastapi nest-asyncio pyngrok uvicorn mysql-connector-python"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1627,"status":"ok","timestamp":1747374561717,"user":{"displayName":"L√™ ƒê√¨nh D∆∞∆°ng - B21DCCN281","userId":"05329236511620356760"},"user_tz":-420},"id":"CUGVMM2GYBMh","outputId":"d877ecdb-16e8-4c00-c015-d3ce52336ad8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}],"source":["!ngrok config add-authtoken 2wp8F8N7kxSiPpYoWHXkzenmEdt_738Ld4iuF3qVEeEYUfbzL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"bZOq_sV9YCCp"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Th∆∞ m·ª•c Drive ƒë√£ k·∫øt n·ªëi t·∫°i: /content/drive/MyDrive/pttk\n","N·ªôi dung th∆∞ m·ª•c DRIVE_BASE_PATH: ['data', 'models']\n","N·ªôi dung th∆∞ m·ª•c BASE_PATH: ['model_3', 'model_4']\n","N·ªôi dung th∆∞ m·ª•c MODEL_PATH: ['model_3']\n"]},{"name":"stderr","output_type":"stream","text":["\u003cipython-input-2-b32f5cf6e88e\u003e:687: DeprecationWarning: \n","        on_event is deprecated, use lifespan event handlers instead.\n","\n","        Read more about it in the\n","        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n","        \n","  @app.on_event(\"startup\")\n"]},{"name":"stdout","output_type":"stream","text":["üåê Public URL: NgrokTunnel: \"https://fb8d-34-13-155-234.ngrok-free.app\" -\u003e \"http://localhost:8000\"\n"]},{"name":"stderr","output_type":"stream","text":["INFO:     Started server process [2961]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"]},{"name":"stdout","output_type":"stream","text":["ƒê√£ t·∫°o th∆∞ m·ª•c: /content/drive/MyDrive/pttk/data v√† /content/drive/MyDrive/pttk/models\n","‚úÖ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh 8: 1\n","INFO:     14.0.22.145:0 - \"GET /train/8 HTTP/1.1\" 200 OK\n","‚úÖ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh 8: 2\n","[M√¥ h√¨nh 8] ƒêang t·∫£i d·ªØ li·ªáu video... (Ti·∫øn ƒë·ªô: 5%)\n","L·∫•y d·ªØ li·ªáu t·ª´ t·∫≠p d·ªØ li·ªáu ID = 1\n","T√¨m th·∫•y 2 video trong t·∫≠p d·ªØ li·ªáu\n","‚úÖ L∆∞u video da v√†o /content/drive/MyDrive/pttk/data/model_8/da\n","‚úÖ L∆∞u video dam v√†o /content/drive/MyDrive/pttk/data/model_8/dam\n","ƒê√£ t·∫£i xong 2/2 video v√†o /content/drive/MyDrive/pttk/data/model_8\n","[M√¥ h√¨nh 8] ƒê√£ t·∫£i xong d·ªØ li·ªáu v√†o /content/drive/MyDrive/pttk/data/model_8, ƒëang kh·ªüi t·∫°o m√¥ h√¨nh... (Ti·∫øn ƒë·ªô: 30%)\n","Th∆∞ m·ª•c nh√£n: ['da', 'dam']\n","Labels: {'da': 0, 'dam': 1}\n","T·∫£i processor t·ª´ facebook/timesformer-base-finetuned-k400\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"]},{"name":"stdout","output_type":"stream","text":["T·∫£i m√¥ h√¨nh t·ª´ facebook/timesformer-base-finetuned-k400 v·ªõi 2 nh√£n\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of TimesformerForVideoClassification were not initialized from the model checkpoint at facebook/timesformer-base-finetuned-k400 and are newly initialized because the shapes did not match:\n","- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([2]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["[M√¥ h√¨nh 8] ƒêang chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán... (Ti·∫øn ƒë·ªô: 40%)\n","T·∫°o dataset t·ª´ /content/drive/MyDrive/pttk/data/model_8\n","ƒê√£ t√¨m th·∫•y 2 nh√£n: {'da': 0, 'dam': 1}\n","T·ªïng s·ªë video: 2\n","[M√¥ h√¨nh 8] ƒêang x·ª≠ l√Ω d·ªØ li·ªáu: 1/2 (Ti·∫øn ƒë·ªô: 40%)\n","[M√¥ h√¨nh 8] B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán v·ªõi 2 m·∫´u video... (Ti·∫øn ƒë·ªô: 50%)\n","S·ª≠ d·ª•ng thi·∫øt b·ªã: cpu\n","[M√¥ h√¨nh 8] Epoch 1/3 - Batch 1/1 (Ti·∫øn ƒë·ªô: 50%)\n","Epoch 1/3 - Loss: 0.8207\n","[M√¥ h√¨nh 8] Epoch 1/3 - Loss: 0.8207 (Ti·∫øn ƒë·ªô: 63.33333333333333%)\n","[M√¥ h√¨nh 8] Epoch 2/3 - Batch 1/1 (Ti·∫øn ƒë·ªô: 63%)\n","Epoch 2/3 - Loss: 0.4206\n","[M√¥ h√¨nh 8] Epoch 2/3 - Loss: 0.4206 (Ti·∫øn ƒë·ªô: 76.66666666666666%)\n","[M√¥ h√¨nh 8] Epoch 3/3 - Batch 1/1 (Ti·∫øn ƒë·ªô: 76%)\n","Epoch 3/3 - Loss: 0.2033\n","[M√¥ h√¨nh 8] Epoch 3/3 - Loss: 0.2033 (Ti·∫øn ƒë·ªô: 90.0%)\n","B·∫Øt ƒë·∫ßu l∆∞u m√¥ h√¨nh v√†o /content/drive/MyDrive/pttk/models/model_8\n","[M√¥ h√¨nh 8] ƒêang l∆∞u m√¥ h√¨nh v√†o Drive t·∫°i /content/drive/MyDrive/pttk/models/model_8... (Ti·∫øn ƒë·ªô: 90%)\n","L∆∞u m√¥ h√¨nh...\n","L∆∞u m√¥ h√¨nh th√†nh c√¥ng\n","L∆∞u processor...\n","L∆∞u processor th√†nh c√¥ng\n","L∆∞u nh√£n v√†o /content/drive/MyDrive/pttk/models/model_8/labels.json\n","Files ƒë√£ l∆∞u trong /content/drive/MyDrive/pttk/models/model_8: ['config.json', 'model.safetensors', 'preprocessor_config.json', 'labels.json']\n","[M√¥ h√¨nh 8] ƒêang c·∫≠p nh·∫≠t th√¥ng tin m√¥ h√¨nh v√†o c∆° s·ªü d·ªØ li·ªáu... (Ti·∫øn ƒë·ªô: 95%)\n","‚úÖ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh 8: 3\n","[M√¥ h√¨nh 8] Hu·∫•n luy·ªán ho√†n t·∫•t! M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u t·∫°i /content/drive/MyDrive/pttk/models/model_8 (Ti·∫øn ƒë·ªô: 100%)\n","‚úÖ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh 7: 1\n","INFO:     14.0.22.145:0 - \"GET /train/7 HTTP/1.1\" 200 OK\n","‚úÖ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh 7: 2\n","[M√¥ h√¨nh 7] ƒêang t·∫£i d·ªØ li·ªáu video... (Ti·∫øn ƒë·ªô: 5%)\n","L·∫•y d·ªØ li·ªáu t·ª´ t·∫≠p d·ªØ li·ªáu ID = 1\n","T√¨m th·∫•y 3 video trong t·∫≠p d·ªØ li·ªáu\n","‚úÖ L∆∞u video da v√†o /content/drive/MyDrive/pttk/data/model_7/da\n","‚úÖ L∆∞u video dam v√†o /content/drive/MyDrive/pttk/data/model_7/dam\n","‚úÖ L∆∞u video mau dam 2 v√†o /content/drive/MyDrive/pttk/data/model_7/dam\n","ƒê√£ t·∫£i xong 3/3 video v√†o /content/drive/MyDrive/pttk/data/model_7\n","[M√¥ h√¨nh 7] ƒê√£ t·∫£i xong d·ªØ li·ªáu v√†o /content/drive/MyDrive/pttk/data/model_7, ƒëang kh·ªüi t·∫°o m√¥ h√¨nh... (Ti·∫øn ƒë·ªô: 30%)\n","Th∆∞ m·ª•c nh√£n: ['da', 'dam']\n","Labels: {'da': 0, 'dam': 1}\n","T·∫£i processor t·ª´ facebook/timesformer-base-finetuned-k400\n","T·∫£i m√¥ h√¨nh t·ª´ facebook/timesformer-base-finetuned-k400 v·ªõi 2 nh√£n\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of TimesformerForVideoClassification were not initialized from the model checkpoint at facebook/timesformer-base-finetuned-k400 and are newly initialized because the shapes did not match:\n","- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([2]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["[M√¥ h√¨nh 7] ƒêang chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán... (Ti·∫øn ƒë·ªô: 40%)\n","T·∫°o dataset t·ª´ /content/drive/MyDrive/pttk/data/model_7\n","ƒê√£ t√¨m th·∫•y 2 nh√£n: {'da': 0, 'dam': 1}\n","T·ªïng s·ªë video: 3\n","[M√¥ h√¨nh 7] ƒêang x·ª≠ l√Ω d·ªØ li·ªáu: 1/3 (Ti·∫øn ƒë·ªô: 40%)\n","[M√¥ h√¨nh 7] B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán v·ªõi 3 m·∫´u video... (Ti·∫øn ƒë·ªô: 50%)\n","S·ª≠ d·ª•ng thi·∫øt b·ªã: cpu\n","[M√¥ h√¨nh 7] Epoch 1/3 - Batch 1/2 (Ti·∫øn ƒë·ªô: 50%)\n","[M√¥ h√¨nh 7] Epoch 1/3 - Batch 2/2 (Ti·∫øn ƒë·ªô: 56%)\n","Epoch 1/3 - Loss: 1.0362\n","[M√¥ h√¨nh 7] Epoch 1/3 - Loss: 1.0362 (Ti·∫øn ƒë·ªô: 63.33333333333333%)\n","[M√¥ h√¨nh 7] Epoch 2/3 - Batch 1/2 (Ti·∫øn ƒë·ªô: 63%)\n","[M√¥ h√¨nh 7] Epoch 2/3 - Batch 2/2 (Ti·∫øn ƒë·ªô: 70%)\n","Epoch 2/3 - Loss: 0.3861\n","[M√¥ h√¨nh 7] Epoch 2/3 - Loss: 0.3861 (Ti·∫øn ƒë·ªô: 76.66666666666666%)\n","[M√¥ h√¨nh 7] Epoch 3/3 - Batch 1/2 (Ti·∫øn ƒë·ªô: 76%)\n","[M√¥ h√¨nh 7] Epoch 3/3 - Batch 2/2 (Ti·∫øn ƒë·ªô: 83%)\n","Epoch 3/3 - Loss: 0.1649\n","[M√¥ h√¨nh 7] Epoch 3/3 - Loss: 0.1649 (Ti·∫øn ƒë·ªô: 90.0%)\n","B·∫Øt ƒë·∫ßu l∆∞u m√¥ h√¨nh v√†o /content/drive/MyDrive/pttk/models/model_7\n","[M√¥ h√¨nh 7] ƒêang l∆∞u m√¥ h√¨nh v√†o Drive t·∫°i /content/drive/MyDrive/pttk/models/model_7... (Ti·∫øn ƒë·ªô: 90%)\n","L∆∞u m√¥ h√¨nh...\n","L∆∞u m√¥ h√¨nh th√†nh c√¥ng\n","L∆∞u processor...\n","L∆∞u processor th√†nh c√¥ng\n","L∆∞u nh√£n v√†o /content/drive/MyDrive/pttk/models/model_7/labels.json\n","Files ƒë√£ l∆∞u trong /content/drive/MyDrive/pttk/models/model_7: ['config.json', 'model.safetensors', 'preprocessor_config.json', 'labels.json']\n","[M√¥ h√¨nh 7] ƒêang c·∫≠p nh·∫≠t th√¥ng tin m√¥ h√¨nh v√†o c∆° s·ªü d·ªØ li·ªáu... (Ti·∫øn ƒë·ªô: 95%)\n","‚úÖ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh 7: 3\n","[M√¥ h√¨nh 7] Hu·∫•n luy·ªán ho√†n t·∫•t! M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u t·∫°i /content/drive/MyDrive/pttk/models/model_7 (Ti·∫øn ƒë·ªô: 100%)\n","‚úÖ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh 9: 1\n","INFO:     14.0.22.145:0 - \"GET /train/9 HTTP/1.1\" 200 OK\n","‚úÖ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh 9: 2\n","[M√¥ h√¨nh 9] ƒêang t·∫£i d·ªØ li·ªáu video... (Ti·∫øn ƒë·ªô: 5%)\n","L·∫•y d·ªØ li·ªáu t·ª´ t·∫≠p d·ªØ li·ªáu ID = 2\n","T√¨m th·∫•y 1 video trong t·∫≠p d·ªØ li·ªáu\n","‚úÖ L∆∞u video da v√†o /content/drive/MyDrive/pttk/data/model_9/da\n","ƒê√£ t·∫£i xong 1/1 video v√†o /content/drive/MyDrive/pttk/data/model_9\n","[M√¥ h√¨nh 9] ƒê√£ t·∫£i xong d·ªØ li·ªáu v√†o /content/drive/MyDrive/pttk/data/model_9, ƒëang kh·ªüi t·∫°o m√¥ h√¨nh... (Ti·∫øn ƒë·ªô: 30%)\n","Th∆∞ m·ª•c nh√£n: ['da']\n","Labels: {'da': 0}\n","T·∫£i processor t·ª´ facebook/timesformer-base-finetuned-k400\n","T·∫£i m√¥ h√¨nh t·ª´ facebook/timesformer-base-finetuned-k400 v·ªõi 1 nh√£n\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of TimesformerForVideoClassification were not initialized from the model checkpoint at facebook/timesformer-base-finetuned-k400 and are newly initialized because the shapes did not match:\n","- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([1, 768]) in the model instantiated\n","- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([1]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["[M√¥ h√¨nh 9] ƒêang chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán... (Ti·∫øn ƒë·ªô: 40%)\n","T·∫°o dataset t·ª´ /content/drive/MyDrive/pttk/data/model_9\n","ƒê√£ t√¨m th·∫•y 1 nh√£n: {'da': 0}\n","T·ªïng s·ªë video: 1\n","[M√¥ h√¨nh 9] ƒêang x·ª≠ l√Ω d·ªØ li·ªáu: 1/1 (Ti·∫øn ƒë·ªô: 40%)\n","[M√¥ h√¨nh 9] B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán v·ªõi 1 m·∫´u video... (Ti·∫øn ƒë·ªô: 50%)\n","S·ª≠ d·ª•ng thi·∫øt b·ªã: cpu\n","[M√¥ h√¨nh 9] Epoch 1/3 - Batch 1/1 (Ti·∫øn ƒë·ªô: 50%)\n","Epoch 1/3 - Loss: 0.0000\n","[M√¥ h√¨nh 9] Epoch 1/3 - Loss: 0.0000 (Ti·∫øn ƒë·ªô: 63.33333333333333%)\n","[M√¥ h√¨nh 9] Epoch 2/3 - Batch 1/1 (Ti·∫øn ƒë·ªô: 63%)\n","Epoch 2/3 - Loss: 0.0000\n","[M√¥ h√¨nh 9] Epoch 2/3 - Loss: 0.0000 (Ti·∫øn ƒë·ªô: 76.66666666666666%)\n","[M√¥ h√¨nh 9] Epoch 3/3 - Batch 1/1 (Ti·∫øn ƒë·ªô: 76%)\n","Epoch 3/3 - Loss: 0.0000\n","[M√¥ h√¨nh 9] Epoch 3/3 - Loss: 0.0000 (Ti·∫øn ƒë·ªô: 90.0%)\n","B·∫Øt ƒë·∫ßu l∆∞u m√¥ h√¨nh v√†o /content/drive/MyDrive/pttk/models/model_9\n","[M√¥ h√¨nh 9] ƒêang l∆∞u m√¥ h√¨nh v√†o Drive t·∫°i /content/drive/MyDrive/pttk/models/model_9... (Ti·∫øn ƒë·ªô: 90%)\n","L∆∞u m√¥ h√¨nh...\n","L∆∞u m√¥ h√¨nh th√†nh c√¥ng\n","L∆∞u processor...\n","L∆∞u processor th√†nh c√¥ng\n","L∆∞u nh√£n v√†o /content/drive/MyDrive/pttk/models/model_9/labels.json\n","Files ƒë√£ l∆∞u trong /content/drive/MyDrive/pttk/models/model_9: ['config.json', 'model.safetensors', 'preprocessor_config.json', 'labels.json']\n","[M√¥ h√¨nh 9] ƒêang c·∫≠p nh·∫≠t th√¥ng tin m√¥ h√¨nh v√†o c∆° s·ªü d·ªØ li·ªáu... (Ti·∫øn ƒë·ªô: 95%)\n","‚úÖ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh 9: 3\n","[M√¥ h√¨nh 9] Hu·∫•n luy·ªán ho√†n t·∫•t! M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u t·∫°i /content/drive/MyDrive/pttk/models/model_9 (Ti·∫øn ƒë·ªô: 100%)\n"]}],"source":["import os\n","import cv2\n","import torch\n","import numpy as np\n","import mysql.connector\n","import requests\n","from torchvision import transforms\n","from transformers import TimesformerForVideoClassification, AutoImageProcessor\n","from torch.utils.data import Dataset, DataLoader\n","from fastapi import FastAPI, Path as FastAPIPath, BackgroundTasks\n","import nest_asyncio\n","from pyngrok import ngrok\n","import uvicorn\n","import asyncio\n","import shutil\n","from typing import Dict, Optional, List\n","import threading\n","import time\n","from datetime import datetime\n","import traceback\n","from google.colab import drive\n","from pathlib import Path\n","import json\n","import pytz\n","\n","# Mount Google Drive (s·∫Ω y√™u c·∫ßu x√°c th·ª±c)\n","drive.mount('/content/drive')\n","\n","# FastAPI setup\n","app = FastAPI(title=\"API Hu·∫•n luy·ªán m√¥ h√¨nh nh·∫≠n di·ªán b·∫°o l·ª±c\")\n","nest_asyncio.apply()\n","\n","# Th√¥ng tin k·∫øt n·ªëi MySQL\n","DB_CONFIG = {\n","    'host': 'sql12.freesqldatabase.com',\n","    'user': 'sql12779017',\n","    'password': 'qCN1zWvYiV',\n","    'database': 'sql12779017',\n","    'port': 3306\n","}\n","\n","# ƒê∆∞·ªùng d·∫´n c∆° s·ªü - l∆∞u trong Google Drive\n","DRIVE_BASE_PATH = \"/content/drive/MyDrive/pttk\"\n","BASE_PATH = os.path.join(DRIVE_BASE_PATH, \"data\")\n","MODEL_PATH = os.path.join(DRIVE_BASE_PATH, \"models\")\n","\n","# T·∫°o th∆∞ m·ª•c trong Google Drive n·∫øu ch∆∞a t·ªìn t·∫°i\n","os.makedirs(DRIVE_BASE_PATH, exist_ok=True)\n","os.makedirs(BASE_PATH, exist_ok=True)\n","os.makedirs(MODEL_PATH, exist_ok=True)\n","\n","# C·∫•u h√¨nh hu·∫•n luy·ªán m·∫∑c ƒë·ªãnh\n","TRAIN_CONFIG = {\n","    \"epochs\": 3,\n","    \"batch_size\": 2,\n","    \"learning_rate\": 1e-5,\n","    \"num_frames\": 8\n","}\n","\n","# Theo d√µi c√°c t√°c v·ª• hu·∫•n luy·ªán\n","training_tasks = {\n","    \"active\": None,  # ID c·ªßa m√¥ h√¨nh ƒëang hu·∫•n luy·ªán\n","    \"queue\": [],     # H√†ng ƒë·ª£i c√°c m√¥ h√¨nh ch·ªù hu·∫•n luy·ªán\n","    \"status\": {}     # Tr·∫°ng th√°i c·ªßa t·ª´ng m√¥ h√¨nh\n","}\n","\n","# Lock ƒë·ªÉ ƒë·ªìng b·ªô h√≥a truy c·∫≠p v√†o training_tasks\n","task_lock = threading.Lock()\n","\n","# H√†m k·∫øt n·ªëi t·ªõi c∆° s·ªü d·ªØ li·ªáu\n","def get_db_connection():\n","    try:\n","        conn = mysql.connector.connect(**DB_CONFIG)\n","        return conn\n","    except Exception as e:\n","        print(f\"L·ªói k·∫øt n·ªëi ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu: {e}\")\n","        return None\n","\n","# H√†m c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh trong database\n","def update_model_status_in_db(model_id: int, trang_thai: int, thoi_gian_bat_dau: datetime = None,\n","                              thoi_gian_ket_thuc: datetime = None, thong_so_huan_luyen: dict = None,\n","                              do_chinh_xac: float = None, duong_dan_mo_hinh: str = None):\n","    try:\n","        conn = get_db_connection()\n","        if not conn:\n","            print(\"Kh√¥ng th·ªÉ k·∫øt n·ªëi CSDL ƒë·ªÉ c·∫≠p nh·∫≠t tr·∫°ng th√°i\")\n","            return False\n","\n","        cursor = conn.cursor()\n","\n","        # X√¢y d·ª±ng c√¢u UPDATE ƒë·ªông d·ª±a tr√™n tham s·ªë\n","        updates = [\"trang_thai = %s\"]\n","        values = [trang_thai]\n","\n","        if thoi_gian_bat_dau:\n","            updates.append(\"thoi_gian_bat_dau = %s\")\n","            values.append(thoi_gian_bat_dau.strftime('%Y-%m-%d %H:%M:%S'))\n","\n","        if thoi_gian_ket_thuc:\n","            updates.append(\"thoi_gian_ket_thuc = %s\")\n","            values.append(thoi_gian_ket_thuc.strftime('%Y-%m-%d %H:%M:%S'))\n","\n","        if thong_so_huan_luyen:\n","            updates.append(\"thong_so_huan_luyen = %s\")\n","            values.append(json.dumps(thong_so_huan_luyen))\n","\n","        if do_chinh_xac is not None:\n","            updates.append(\"do_chinh_xac = %s\")\n","            values.append(do_chinh_xac)\n","\n","        if duong_dan_mo_hinh:\n","            updates.append(\"duong_dan_mo_hinh = %s\")\n","            values.append(duong_dan_mo_hinh)\n","\n","        # Th√™m ƒëi·ªÅu ki·ªán WHERE\n","        update_query = f\"\"\"\n","        UPDATE mo_hinh_da_huan_luyen\n","        SET {', '.join(updates)}\n","        WHERE id = %s\n","        \"\"\"\n","        values.append(model_id)\n","\n","        cursor.execute(update_query, values)\n","        conn.commit()\n","\n","        print(f\"‚úÖ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i m√¥ h√¨nh {model_id}: {trang_thai}\")\n","        cursor.close()\n","        conn.close()\n","        return True\n","\n","    except Exception as e:\n","        print(f\"L·ªói c·∫≠p nh·∫≠t tr·∫°ng th√°i CSDL: {e}\")\n","        print(traceback.format_exc())\n","        return False\n","\n","# H√†m tr√≠ch xu·∫•t frames t·ª´ video\n","def extract_frames(video_path, num_frames=8):\n","    cap = cv2.VideoCapture(video_path)\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    if total_frames \u003c num_frames:\n","        print(f\"‚ö† Video {video_path} qu√° ng·∫Øn!\")\n","        return None\n","\n","    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n","    frames = []\n","\n","    for idx in frame_indices:\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Chuy·ªÉn v·ªÅ RGB\n","        frames.append(frame)\n","\n","    cap.release()\n","    return frames if len(frames) == num_frames else None\n","\n","# Dataset ƒë·ªçc tr·ª±c ti·∫øp video\n","class ActionVideoDataset(Dataset):\n","    def __init__(self, data_folder, processor, num_frames=8):\n","        self.data_folder = data_folder\n","        self.processor = processor\n","        self.num_frames = num_frames\n","        self.video_paths = []\n","        self.targets = []\n","        self.labels = {}\n","\n","        # L·∫•y nh√£n t·ª´ c·∫•u tr√∫c th∆∞ m·ª•c\n","        label_id = 0\n","        for action in os.listdir(data_folder):\n","            action_path = os.path.join(data_folder, action)\n","            if os.path.isdir(action_path):\n","                self.labels[action] = label_id\n","                label_id += 1\n","\n","                # L·∫•y t·∫•t c·∫£ video trong th∆∞ m·ª•c nh√£n\n","                for video in os.listdir(action_path):\n","                    if video.endswith(('.mp4', '.avi')):\n","                        video_path = os.path.join(action_path, video)\n","                        self.video_paths.append(video_path)\n","                        self.targets.append(self.labels[action])\n","\n","        print(f\"ƒê√£ t√¨m th·∫•y {len(self.labels)} nh√£n: {self.labels}\")\n","        print(f\"T·ªïng s·ªë video: {len(self.video_paths)}\")\n","\n","    def __len__(self):\n","        return len(self.video_paths)\n","\n","    def __getitem__(self, idx):\n","        video_path = self.video_paths[idx]\n","        label = self.targets[idx]\n","\n","        frames = extract_frames(video_path, num_frames=self.num_frames)\n","        if frames is None:\n","            return None\n","\n","        inputs = self.processor(images=frames, return_tensors=\"pt\")\n","        return inputs[\"pixel_values\"].squeeze(0), torch.tensor(label)\n","\n","# H√†m t·∫£i video t·ª´ c∆° s·ªü d·ªØ li·ªáu\n","def download_videos_for_model(model_id: int):\n","    try:\n","        conn = get_db_connection()\n","        if not conn:\n","            return False, \"Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu\"\n","\n","        cursor = conn.cursor(dictionary=True)\n","\n","        # T·∫°o th∆∞ m·ª•c ch√≠nh n·∫øu ch∆∞a t·ªìn t·∫°i\n","        model_data_path = os.path.join(BASE_PATH, f\"model_{model_id}\")\n","        if os.path.exists(model_data_path):\n","            print(f\"X√≥a th∆∞ m·ª•c d·ªØ li·ªáu c≈©: {model_data_path}\")\n","            shutil.rmtree(model_data_path)  # X√≥a th∆∞ m·ª•c c≈© n·∫øu t·ªìn t·∫°i\n","        os.makedirs(model_data_path, exist_ok=True)\n","\n","        # 1. L·∫•y th√¥ng tin v·ªÅ m√¥ h√¨nh\n","        cursor.execute(\"SELECT * FROM mo_hinh_da_huan_luyen WHERE id = %s\", (model_id,))\n","        model = cursor.fetchone()\n","        if not model:\n","            cursor.close()\n","            conn.close()\n","            return False, f\"Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh c√≥ ID = {model_id}\"\n","\n","        tap_du_lieu_id = model['tap_du_lieu_id']\n","        print(f\"L·∫•y d·ªØ li·ªáu t·ª´ t·∫≠p d·ªØ li·ªáu ID = {tap_du_lieu_id}\")\n","\n","        # 2. L·∫•y c√°c m·∫´u b·∫°o l·ª±c thu·ªôc t·∫≠p d·ªØ li·ªáu ƒë√≥\n","        query = \"\"\"\n","        SELECT mbl.*\n","        FROM tap_du_lieu_mau tdm\n","        JOIN mau_bao_luc mbl ON tdm.mau_bao_luc_id = mbl.id\n","        WHERE tdm.tap_du_lieu_id = %s\n","        \"\"\"\n","        cursor.execute(query, (tap_du_lieu_id,))\n","        videos = cursor.fetchall()\n","\n","        if not videos:\n","            cursor.close()\n","            conn.close()\n","            return False, f\"Kh√¥ng c√≥ video n√†o trong t·∫≠p d·ªØ li·ªáu ID = {tap_du_lieu_id}\"\n","\n","        print(f\"T√¨m th·∫•y {len(videos)} video trong t·∫≠p d·ªØ li·ªáu\")\n","\n","        # 3. T·∫°o th∆∞ m·ª•c v√† t·∫£i video\n","        video_count = 0\n","        for video in videos:\n","            duong_dan = video['duong_dan_video']\n","            nhan = video['nhan'] or \"unknown\"\n","            ten = video['ten'] or f\"video_{video['id']}\"\n","\n","            folder_path = os.path.join(model_data_path, nhan)\n","            os.makedirs(folder_path, exist_ok=True)\n","\n","            try:\n","                response = requests.get(duong_dan, stream=True, timeout=30)\n","                if response.status_code == 200:\n","                    video_path = os.path.join(folder_path, f\"{ten}.mp4\")\n","                    with open(video_path, 'wb') as f:\n","                        for chunk in response.iter_content(chunk_size=8192):\n","                            f.write(chunk)\n","                    print(f\"‚úÖ L∆∞u video {ten} v√†o {folder_path}\")\n","                    video_count += 1\n","                else:\n","                    print(f\"‚ùå Kh√¥ng th·ªÉ t·∫£i {duong_dan} (status {response.status_code})\")\n","\n","                # C·∫≠p nh·∫≠t tr·∫°ng th√°i\n","                with task_lock:\n","                    if model_id in training_tasks[\"status\"]:\n","                        training_tasks[\"status\"][model_id][\"progress\"] = 10 + (video_count / len(videos) * 20)\n","                        training_tasks[\"status\"][model_id][\"message\"] = f\"ƒê√£ t·∫£i {video_count}/{len(videos)} video\"\n","\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è L·ªói k·∫øt n·ªëi ƒë·∫øn {duong_dan}: {e}\")\n","\n","        cursor.close()\n","        conn.close()\n","\n","        if video_count == 0:\n","            return False, \"Kh√¥ng t·∫£i ƒë∆∞·ª£c video n√†o\"\n","\n","        print(f\"ƒê√£ t·∫£i xong {video_count}/{len(videos)} video v√†o {model_data_path}\")\n","        return True, model_data_path\n","\n","    except Exception as e:\n","        print(f\"L·ªói trong qu√° tr√¨nh t·∫£i video: {e}\")\n","        print(traceback.format_exc())\n","        return False, f\"L·ªói: {str(e)}\"\n","\n","# H√†m hu·∫•n luy·ªán m√¥ h√¨nh (ch·∫°y trong thread ri√™ng)\n","def train_model_task(model_id: int):\n","    try:\n","        # Th·ªùi gian b·∫Øt ƒë·∫ßu\n","        start_time = datetime.now(pytz.timezone('Asia/Ho_Chi_Minh'))\n","\n","        # C·∫≠p nh·∫≠t tr·∫°ng th√°i b·∫Øt ƒë·∫ßu hu·∫•n luy·ªán (2) v√† th·ªùi gian b·∫Øt ƒë·∫ßu\n","        update_model_status_in_db(model_id, 2, datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')))\n","\n","        # C·∫≠p nh·∫≠t tr·∫°ng th√°i\n","        with task_lock:\n","            training_tasks[\"active\"] = model_id\n","            training_tasks[\"status\"][model_id] = {\n","                \"start_time\": start_time.isoformat(),\n","                \"progress\": 0,\n","                \"message\": \"Kh·ªüi ƒë·ªông qu√° tr√¨nh hu·∫•n luy·ªán...\",\n","                \"completed\": False,\n","                \"success\": False\n","            }\n","\n","        # C·∫≠p nh·∫≠t tr·∫°ng th√°i\n","        def update_status(progress, message):\n","            print(f\"[M√¥ h√¨nh {model_id}] {message} (Ti·∫øn ƒë·ªô: {progress}%)\")\n","            with task_lock:\n","                if model_id in training_tasks[\"status\"]:\n","                    training_tasks[\"status\"][model_id][\"progress\"] = progress\n","                    training_tasks[\"status\"][model_id][\"message\"] = message\n","\n","        update_status(5, \"ƒêang t·∫£i d·ªØ li·ªáu video...\")\n","\n","        # T·∫£i video t·ª´ c∆° s·ªü d·ªØ li·ªáu\n","        success, result = download_videos_for_model(model_id)\n","        if not success:\n","            update_status(0, f\"L·ªói t·∫£i d·ªØ li·ªáu: {result}\")\n","            with task_lock:\n","                training_tasks[\"active\"] = None\n","                training_tasks[\"status\"][model_id][\"completed\"] = True\n","                training_tasks[\"status\"][model_id][\"success\"] = False\n","            process_next_in_queue()\n","            return False\n","\n","        data_path = result\n","        update_status(30, f\"ƒê√£ t·∫£i xong d·ªØ li·ªáu v√†o {data_path}, ƒëang kh·ªüi t·∫°o m√¥ h√¨nh...\")\n","\n","        # Ki·ªÉm tra xem c√≥ th∆∞ m·ª•c nh√£n n√†o kh√¥ng\n","        label_dirs = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n","        if not label_dirs:\n","            update_status(0, \"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c nh√£n trong d·ªØ li·ªáu\")\n","            with task_lock:\n","                training_tasks[\"active\"] = None\n","                training_tasks[\"status\"][model_id][\"completed\"] = True\n","                training_tasks[\"status\"][model_id][\"success\"] = False\n","            process_next_in_queue()\n","            return False\n","\n","        print(f\"Th∆∞ m·ª•c nh√£n: {label_dirs}\")\n","\n","        # T·∫°o ƒë·ªëi t∆∞·ª£ng labels t·ª´ th∆∞ m·ª•c\n","        labels_dict = {label: idx for idx, label in enumerate(label_dirs)}\n","        num_labels = len(labels_dict)\n","        print(f\"Labels: {labels_dict}\")\n","\n","        # Kh·ªüi t·∫°o m√¥ h√¨nh v√† processor\n","        model_name = \"facebook/timesformer-base-finetuned-k400\"\n","        print(f\"T·∫£i processor t·ª´ {model_name}\")\n","        processor = AutoImageProcessor.from_pretrained(model_name)\n","\n","        print(f\"T·∫£i m√¥ h√¨nh t·ª´ {model_name} v·ªõi {num_labels} nh√£n\")\n","        model = TimesformerForVideoClassification.from_pretrained(\n","            model_name,\n","            num_labels=num_labels,\n","            ignore_mismatched_sizes=True\n","        )\n","\n","        update_status(40, \"ƒêang chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán...\")\n","\n","        # Chu·∫©n b·ªã d·ªØ li·ªáu\n","        print(f\"T·∫°o dataset t·ª´ {data_path}\")\n","        train_dataset = ActionVideoDataset(data_path, processor, num_frames=TRAIN_CONFIG[\"num_frames\"])\n","\n","        if len(train_dataset) == 0:\n","            update_status(0, \"Kh√¥ng c√≥ d·ªØ li·ªáu hu·∫•n luy·ªán h·ª£p l·ªá\")\n","            with task_lock:\n","                training_tasks[\"active\"] = None\n","                training_tasks[\"status\"][model_id][\"completed\"] = True\n","                training_tasks[\"status\"][model_id][\"success\"] = False\n","            process_next_in_queue()\n","            return False\n","\n","        # L·ªçc c√°c m·∫´u h·ª£p l·ªá (kh√¥ng None)\n","        valid_data = []\n","        for i in range(len(train_dataset)):\n","            item = train_dataset[i]\n","            if item is not None:\n","                valid_data.append(item)\n","\n","            # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh\n","            if i % 5 == 0:\n","                update_status(40 + int((i / len(train_dataset)) * 10),\n","                              f\"ƒêang x·ª≠ l√Ω d·ªØ li·ªáu: {i+1}/{len(train_dataset)}\")\n","\n","        if not valid_data:\n","            update_status(0, \"Kh√¥ng t√¨m th·∫•y m·∫´u video h·ª£p l·ªá n√†o\")\n","            with task_lock:\n","                training_tasks[\"active\"] = None\n","                training_tasks[\"status\"][model_id][\"completed\"] = True\n","                training_tasks[\"status\"][model_id][\"success\"] = False\n","            process_next_in_queue()\n","            return False\n","\n","        # T·∫°o DataLoader\n","        train_loader = DataLoader(valid_data, batch_size=TRAIN_CONFIG[\"batch_size\"], shuffle=True)\n","\n","        update_status(50, f\"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán v·ªõi {len(valid_data)} m·∫´u video...\")\n","\n","        # Hu·∫•n luy·ªán m√¥ h√¨nh\n","        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        print(f\"S·ª≠ d·ª•ng thi·∫øt b·ªã: {device}\")\n","        model.to(device)\n","        optimizer = torch.optim.AdamW(model.parameters(), lr=TRAIN_CONFIG[\"learning_rate\"])\n","        loss_fn = torch.nn.CrossEntropyLoss()\n","\n","        avg_loss = 0\n","        for epoch in range(TRAIN_CONFIG[\"epochs\"]):\n","            model.train()\n","            total_loss = 0\n","            batch_count = 0\n","\n","            for batch_idx, batch in enumerate(train_loader):\n","                inputs, targets = batch\n","                inputs, targets = inputs.to(device), targets.to(device)\n","\n","                optimizer.zero_grad()\n","                outputs = model(pixel_values=inputs)\n","                loss = loss_fn(outputs.logits, targets)\n","                loss.backward()\n","                optimizer.step()\n","\n","                total_loss += loss.item()\n","                batch_count += 1\n","\n","                # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh\n","                progress_per_epoch = 40 / TRAIN_CONFIG[\"epochs\"]\n","                current_epoch_progress = (batch_idx / len(train_loader)) * progress_per_epoch\n","                update_status(50 + int((epoch * progress_per_epoch) + current_epoch_progress),\n","                              f\"Epoch {epoch+1}/{TRAIN_CONFIG['epochs']} - Batch {batch_idx+1}/{len(train_loader)}\")\n","\n","            avg_loss = total_loss / batch_count if batch_count \u003e 0 else 0\n","            print(f\"Epoch {epoch+1}/{TRAIN_CONFIG['epochs']} - Loss: {avg_loss:.4f}\")\n","            update_status(50 + ((epoch+1) / TRAIN_CONFIG[\"epochs\"]) * 40,\n","                          f\"Epoch {epoch+1}/{TRAIN_CONFIG['epochs']} - Loss: {avg_loss:.4f}\")\n","\n","        # L∆∞u m√¥ h√¨nh v√†o Google Drive\n","        try:\n","            model_save_path = os.path.join(MODEL_PATH, f\"model_{model_id}\")\n","            print(f\"B·∫Øt ƒë·∫ßu l∆∞u m√¥ h√¨nh v√†o {model_save_path}\")\n","\n","            if os.path.exists(model_save_path):\n","                print(f\"X√≥a th∆∞ m·ª•c m√¥ h√¨nh c≈©: {model_save_path}\")\n","                shutil.rmtree(model_save_path)\n","\n","            os.makedirs(model_save_path, exist_ok=True)\n","\n","            update_status(90, f\"ƒêang l∆∞u m√¥ h√¨nh v√†o Drive t·∫°i {model_save_path}...\")\n","\n","            # L∆∞u m√¥ h√¨nh\n","            print(f\"L∆∞u m√¥ h√¨nh...\")\n","            model.save_pretrained(model_save_path)\n","            print(f\"L∆∞u m√¥ h√¨nh th√†nh c√¥ng\")\n","\n","            # L∆∞u processor\n","            print(f\"L∆∞u processor...\")\n","            processor.save_pretrained(model_save_path)\n","            print(f\"L∆∞u processor th√†nh c√¥ng\")\n","\n","            # L∆∞u th√¥ng tin nh√£n\n","            labels_file = os.path.join(model_save_path, \"labels.json\")\n","            print(f\"L∆∞u nh√£n v√†o {labels_file}\")\n","            with open(labels_file, \"w\") as f:\n","                json.dump(labels_dict, f)\n","\n","            # Ki·ªÉm tra files ƒë√£ l∆∞u\n","            saved_files = os.listdir(model_save_path)\n","            print(f\"Files ƒë√£ l∆∞u trong {model_save_path}: {saved_files}\")\n","\n","            update_status(95, \"ƒêang c·∫≠p nh·∫≠t th√¥ng tin m√¥ h√¨nh v√†o c∆° s·ªü d·ªØ li·ªáu...\")\n","        except Exception as e:\n","            print(f\"L·ªói khi l∆∞u m√¥ h√¨nh: {e}\")\n","            print(traceback.format_exc())\n","\n","        # Chu·∫©n b·ªã th√¥ng tin c·∫≠p nh·∫≠t\n","        accuracy = float(1.0 - avg_loss) if avg_loss \u003c= 1.0 else 0.1\n","        absolute_model_path = os.path.abspath(model_save_path)\n","\n","        # Chu·∫©n b·ªã th√¥ng s·ªë hu·∫•n luy·ªán d·∫°ng JSON\n","        thong_so_huan_luyen = {\n","            \"epochs\": TRAIN_CONFIG[\"epochs\"],\n","            \"batch_size\": TRAIN_CONFIG[\"batch_size\"],\n","            \"learning_rate\": TRAIN_CONFIG[\"learning_rate\"],\n","            \"num_frames\": TRAIN_CONFIG[\"num_frames\"],\n","            \"num_labels\": num_labels,\n","            \"labels\": labels_dict,\n","            \"model_name\": model_name,\n","            \"device\": device,\n","            \"final_loss\": avg_loss,\n","            \"num_training_samples\": len(valid_data)\n","        }\n","\n","        end_time = datetime.now(pytz.timezone('Asia/Ho_Chi_Minh'))\n","\n","        # C·∫≠p nh·∫≠t t·∫•t c·∫£ th√¥ng tin v√†o database v·ªõi tr·∫°ng th√°i ho√†n th√†nh (3)\n","        update_model_status_in_db(\n","            model_id=model_id,\n","            trang_thai=3,\n","            thoi_gian_bat_dau=start_time,\n","            thoi_gian_ket_thuc=end_time,\n","            thong_so_huan_luyen=thong_so_huan_luyen,\n","            do_chinh_xac=accuracy,\n","            duong_dan_mo_hinh=absolute_model_path\n","        )\n","\n","        update_status(100, f\"Hu·∫•n luy·ªán ho√†n t·∫•t! M√¥ h√¨nh ƒë∆∞·ª£c l∆∞u t·∫°i {model_save_path}\")\n","\n","        # ƒê√°nh d·∫•u ho√†n th√†nh\n","        with task_lock:\n","            training_tasks[\"active\"] = None\n","            training_tasks[\"status\"][model_id][\"completed\"] = True\n","            training_tasks[\"status\"][model_id][\"success\"] = True\n","            training_tasks[\"status\"][model_id][\"end_time\"] = end_time.isoformat()\n","\n","        # X·ª≠ l√Ω m√¥ h√¨nh ti·∫øp theo trong h√†ng ƒë·ª£i\n","        process_next_in_queue()\n","\n","        return True\n","\n","    except Exception as e:\n","        print(f\"L·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán: {e}\")\n","        print(traceback.format_exc())\n","\n","        # C·∫≠p nh·∫≠t tr·∫°ng th√°i l·ªói\n","        update_model_status_in_db(model_id, 3, thoi_gian_ket_thuc=datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')))\n","\n","        with task_lock:\n","            if model_id in training_tasks[\"status\"]:\n","                training_tasks[\"status\"][model_id][\"message\"] = f\"L·ªói hu·∫•n luy·ªán: {str(e)}\"\n","                training_tasks[\"status\"][model_id][\"completed\"] = True\n","                training_tasks[\"status\"][model_id][\"success\"] = False\n","                training_tasks[\"status\"][model_id][\"end_time\"] = datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')).isoformat()\n","            training_tasks[\"active\"] = None\n","\n","        # X·ª≠ l√Ω m√¥ h√¨nh ti·∫øp theo trong h√†ng ƒë·ª£i\n","        process_next_in_queue()\n","\n","        return False\n","\n","# X·ª≠ l√Ω m√¥ h√¨nh ti·∫øp theo trong h√†ng ƒë·ª£i\n","def process_next_in_queue():\n","    with task_lock:\n","        if not training_tasks[\"queue\"] or training_tasks[\"active\"] is not None:\n","            return\n","\n","        # L·∫•y m√¥ h√¨nh ti·∫øp theo t·ª´ h√†ng ƒë·ª£i\n","        next_model_id = training_tasks[\"queue\"].pop(0)\n","        print(f\"Ti·∫øp t·ª•c x·ª≠ l√Ω m√¥ h√¨nh ti·∫øp theo trong h√†ng ƒë·ª£i: {next_model_id}\")\n","\n","        # Kh·ªüi ƒë·ªông m·ªôt thread m·ªõi ƒë·ªÉ hu·∫•n luy·ªán\n","        # update_model_status_in_db(next_model_id, 2, datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')))\n","        thread = threading.Thread(target=train_model_task, args=(next_model_id,))\n","        thread.daemon = True\n","        thread.start()\n","\n","# API endpoint th√™m m√¥ h√¨nh v√†o h√†ng ƒë·ª£i hu·∫•n luy·ªán\n","@app.get(\"/train/{model_id}\")\n","async def trigger_training(model_id: int = FastAPIPath(..., description=\"ID c·ªßa m√¥ h√¨nh c·∫ßn hu·∫•n luy·ªán\")):\n","    # Ki·ªÉm tra ID m√¥ h√¨nh trong c∆° s·ªü d·ªØ li·ªáu\n","    conn = get_db_connection()\n","    if not conn:\n","        return {\"success\": False, \"message\": \"Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu\"}\n","\n","    cursor = conn.cursor(dictionary=True)\n","    cursor.execute(\"SELECT id FROM mo_hinh_da_huan_luyen WHERE id = %s\", (model_id,))\n","    model = cursor.fetchone()\n","    cursor.close()\n","    conn.close()\n","\n","    if not model:\n","        return {\"success\": False, \"message\": f\"Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh c√≥ ID = {model_id}\"}\n","\n","    # Ki·ªÉm tra xem m√¥ h√¨nh ƒë√£ trong h√†ng ƒë·ª£i ho·∫∑c ƒëang hu·∫•n luy·ªán ch∆∞a\n","    with task_lock:\n","        if model_id == training_tasks[\"active\"]:\n","            return {\n","                \"success\": False,\n","                \"message\": f\"M√¥ h√¨nh ID: {model_id} ƒëang ƒë∆∞·ª£c hu·∫•n luy·ªán\",\n","                \"status\": training_tasks[\"status\"].get(model_id, {})\n","            }\n","\n","        if model_id in training_tasks[\"queue\"]:\n","            position = training_tasks[\"queue\"].index(model_id) + 1\n","            return {\n","                \"success\": False,\n","                \"message\": f\"M√¥ h√¨nh ID: {model_id} ƒë√£ trong h√†ng ƒë·ª£i ·ªü v·ªã tr√≠ {position}\",\n","                \"queue_position\": position\n","            }\n","\n","        # Th√™m v√†o h√†ng ƒë·ª£i\n","        if model_id in training_tasks[\"status\"] and not training_tasks[\"status\"][model_id][\"completed\"]:\n","            # M√¥ h√¨nh ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω\n","            return {\n","                \"success\": False,\n","                \"message\": f\"M√¥ h√¨nh ID: {model_id} ƒëang trong qu√° tr√¨nh x·ª≠ l√Ω\",\n","                \"status\": training_tasks[\"status\"].get(model_id, {})\n","            }\n","\n","        # Kh·ªüi t·∫°o tr·∫°ng th√°i\n","        training_tasks[\"status\"][model_id] = {\n","            \"queued_time\": datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')).isoformat(),\n","            \"progress\": 0,\n","            \"message\": \"ƒêang ch·ªù trong h√†ng ƒë·ª£i\",\n","            \"completed\": False,\n","            \"success\": False\n","        }\n","\n","        # C·∫≠p nh·∫≠t tr·∫°ng th√°i queue (1) v√†o database\n","        update_model_status_in_db(model_id, 1)\n","\n","        # N·∫øu kh√¥ng c√≥ m√¥ h√¨nh n√†o ƒëang hu·∫•n luy·ªán, b·∫Øt ƒë·∫ßu hu·∫•n luy·ªán ngay\n","        if training_tasks[\"active\"] is None:\n","            # Kh·ªüi ƒë·ªông thread m·ªõi ƒë·ªÉ hu·∫•n luy·ªán\n","            # update_model_status_in_db(model_id, 2, datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')))\n","            thread = threading.Thread(target=train_model_task, args=(model_id,))\n","            thread.daemon = True\n","            thread.start()\n","            return {\n","                \"success\": True,\n","                \"message\": f\"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh ID: {model_id}\",\n","                \"queue_position\": 0\n","            }\n","        else:\n","            # Th√™m v√†o h√†ng ƒë·ª£i\n","            training_tasks[\"queue\"].append(model_id)\n","            queue_position = len(training_tasks[\"queue\"])\n","            return {\n","                \"success\": True,\n","                \"message\": f\"ƒê√£ th√™m m√¥ h√¨nh ID: {model_id} v√†o h√†ng ƒë·ª£i hu·∫•n luy·ªán\",\n","                \"queue_position\": queue_position\n","            }\n","\n","# API endpoint ki·ªÉm tra tr·∫°ng th√°i hu·∫•n luy·ªán\n","@app.get(\"/status\")\n","async def get_status():\n","    with task_lock:\n","        active_model = training_tasks[\"active\"]\n","        active_status = training_tasks[\"status\"].get(active_model, {}) if active_model else None\n","        queue_size = len(training_tasks[\"queue\"])\n","        queue_models = training_tasks[\"queue\"].copy()\n","\n","        # L·∫•y tr·∫°ng th√°i c·ªßa t·∫•t c·∫£ c√°c m√¥ h√¨nh\n","        all_models_status = {model_id: status for model_id, status in training_tasks[\"status\"].items()}\n","\n","        return {\n","            \"active_model\": active_model,\n","            \"active_status\": active_status,\n","            \"queue_size\": queue_size,\n","            \"queue_models\": queue_models,\n","            \"all_models_status\": all_models_status\n","        }\n","\n","# API endpoint ki·ªÉm tra tr·∫°ng th√°i m·ªôt m√¥ h√¨nh c·ª• th·ªÉ\n","@app.get(\"/status/{model_id}\")\n","async def get_model_status(model_id: int = FastAPIPath(..., description=\"ID c·ªßa m√¥ h√¨nh c·∫ßn ki·ªÉm tra\")):\n","    with task_lock:\n","        if model_id not in training_tasks[\"status\"]:\n","            return {\"success\": False, \"message\": f\"Kh√¥ng t√¨m th·∫•y tr·∫°ng th√°i cho m√¥ h√¨nh ID: {model_id}\"}\n","\n","        status = training_tasks[\"status\"][model_id]\n","        is_active = (training_tasks[\"active\"] == model_id)\n","\n","        if not is_active and not status[\"completed\"]:\n","            # M√¥ h√¨nh ƒëang trong h√†ng ƒë·ª£i\n","            queue_position = training_tasks[\"queue\"].index(model_id) + 1 if model_id in training_tasks[\"queue\"] else 0\n","            return {\n","                \"success\": True,\n","                \"is_active\": False,\n","                \"is_queued\": True,\n","                \"queue_position\": queue_position,\n","                \"status\": status\n","            }\n","\n","        return {\n","            \"success\": True,\n","            \"is_active\": is_active,\n","            \"is_queued\": False,\n","            \"status\": status\n","        }\n","\n","# Kh·ªüi t·∫°o ·ª©ng d·ª•ng\n","@app.on_event(\"startup\")\n","async def startup_event():\n","    # T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ n·∫øu ch∆∞a t·ªìn t·∫°i\n","    os.makedirs(BASE_PATH, exist_ok=True)\n","    os.makedirs(MODEL_PATH, exist_ok=True)\n","    print(f\"ƒê√£ t·∫°o th∆∞ m·ª•c: {BASE_PATH} v√† {MODEL_PATH}\")\n","\n","# API endpoint x√≥a tr·∫°ng th√°i c·ªßa m·ªôt m√¥ h√¨nh (ƒë·ªÉ l√†m s·∫°ch)\n","@app.delete(\"/status/{model_id}\")\n","async def delete_model_status(model_id: int = FastAPIPath(..., description=\"ID c·ªßa m√¥ h√¨nh c·∫ßn x√≥a tr·∫°ng th√°i\")):\n","    with task_lock:\n","        if model_id not in training_tasks[\"status\"]:\n","            return {\"success\": False, \"message\": f\"Kh√¥ng t√¨m th·∫•y tr·∫°ng th√°i cho m√¥ h√¨nh ID: {model_id}\"}\n","\n","        if model_id == training_tasks[\"active\"]:\n","            return {\"success\": False, \"message\": f\"Kh√¥ng th·ªÉ x√≥a tr·∫°ng th√°i c·ªßa m√¥ h√¨nh ƒëang hu·∫•n luy·ªán\"}\n","\n","        if model_id in training_tasks[\"queue\"]:\n","            training_tasks[\"queue\"].remove(model_id)\n","\n","        del training_tasks[\"status\"][model_id]\n","\n","        return {\"success\": True, \"message\": f\"ƒê√£ x√≥a tr·∫°ng th√°i c·ªßa m√¥ h√¨nh ID: {model_id}\"}\n","\n","# Ch·∫°y ·ª©ng d·ª•ng\n","if __name__ == \"__main__\":\n","    try:\n","        # Ki·ªÉm tra k·∫øt n·ªëi Drive\n","        print(f\"Th∆∞ m·ª•c Drive ƒë√£ k·∫øt n·ªëi t·∫°i: {DRIVE_BASE_PATH}\")\n","        print(f\"N·ªôi dung th∆∞ m·ª•c DRIVE_BASE_PATH: {os.listdir(DRIVE_BASE_PATH) if os.path.exists(DRIVE_BASE_PATH) else 'Kh√¥ng t·ªìn t·∫°i'}\")\n","        print(f\"N·ªôi dung th∆∞ m·ª•c BASE_PATH: {os.listdir(BASE_PATH) if os.path.exists(BASE_PATH) else 'Kh√¥ng t·ªìn t·∫°i'}\")\n","        print(f\"N·ªôi dung th∆∞ m·ª•c MODEL_PATH: {os.listdir(MODEL_PATH) if os.path.exists(MODEL_PATH) else 'Kh√¥ng t·ªìn t·∫°i'}\")\n","\n","        # Kh·ªüi ƒë·ªông ngrok\n","        public_url = ngrok.connect(8000)\n","        print(f\"üåê Public URL: {public_url}\")\n","\n","        # Ch·∫°y FastAPI\n","        uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n","    except Exception as e:\n","        print(f\"L·ªói kh·ªüi ƒë·ªông ·ª©ng d·ª•ng: {e}\")\n","        print(traceback.format_exc())"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPf/9gJw2Ct75mx3IJPBQ6+","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}